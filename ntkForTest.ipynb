{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! venv/bin/ python3\n",
    "# *-encoding: utf8 -*\n",
    "\n",
    "import requests as rqs\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "def unixTimeStampConvert(num):\n",
    "    convert = datetime.datetime.fromtimestamp(int(num)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONEXION AL SERVIDOR (SITIO WEB), Y REQUEST (PETICION).\n",
    "# **********************************************************\n",
    "# A que sitio me quiero conectar, parametro y URI\n",
    "myurl = \"https://votaciones.hcdn.gob.ar\"\n",
    "# Los siguientes datos los saque de la misma pagina, mirando el codigo fuente para ver\n",
    "# como enviaba las peticiones y cual debia enviar para obtener todos los datos =)\n",
    "formQuery = {'anoSearch': -1, 'txtSearch': ''}\n",
    "endPoint = \"https://votaciones.hcdn.gob.ar/votaciones/search\"\n",
    "\n",
    "# Peticion al servidor\n",
    "r = rqs.post(endPoint, data=formQuery)\n",
    "\n",
    "# Estado de la conexion\n",
    "status = r.status_code\n",
    "\n",
    "if status == 200:\n",
    "    print(f'Conectando a {myurl}')\n",
    "    print(f'Estado de la conexion :: {status}')\n",
    "else:\n",
    "    print('La conexion no se establecio correctamente')\n",
    "    print(f'Codigo estado : {status}')\n",
    "    quit()\n",
    "# **********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de programar el scraper deberiamos saber bien cuanl es el objeto html que contiene la informacion que\n",
    "# queremos por ejemplo, cual es el tag que contiene la info que queremos.\n",
    "# podemos identificar el objeto con la informacion a traves del nombre del Tag, del selctor css, \"class\", del id, etc\n",
    "\n",
    "# El elemento que me interesa tiene la clase \"row-acta\"\n",
    "clase = \"row-acta\"\n",
    "\n",
    "# Creo el objeto BeautifulSoup\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "# El tipo de dato es un result set de beautiful soup, es un iterable, algo asi como una lista\n",
    "datos = soup.find_all(\"tr\", class_=clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACCION DE LAS URLS DONDE ESTAN LOS DETALLES DE CADA VOTACION\n",
    "# **********************************************************\n",
    "urlActas = list()\n",
    "for t in datos:\n",
    "    # Columnas\n",
    "    cols = t.find_all('td')\n",
    "    idActa = t['id'],  # Seria Clave principal\n",
    "    date = unixTimeStampConvert(t['data-date']) # Tengo que convertir el formato de la fecha en human friendly =)\n",
    "    # Me voy a guardar los datos que extraje en una lista de tuplas\n",
    "    urlActas.append((myurl + cols[4].find('a')['href'], idActa, date))\n",
    "# **********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORRIDO DE LAS ACTAS Y SCRAPING DE LOS DETALLES - ACTAS Y VOTACION\n",
    "# **********************************************************\n",
    "actas = list()\n",
    "votaciones = list()\n",
    "for a in urlActas:\n",
    "    #Conexion a cada Acta # *********************************\n",
    "    r = rqs.get(a[0])\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    idActa = a[1]\n",
    "    dateActa = a[2]\n",
    "    urlActa = a[0]\n",
    "\n",
    "    # VAmos a recuperar estos datos -> Período 123 - Reunión 40 - Acta 31\n",
    "    text = soup.find('h5').text.split('-')\n",
    "    periodo = text[0].split()[1]\n",
    "    reunion = text[1].split()[1]\n",
    "    acta = text[2].split()[1]\n",
    "\n",
    "\n",
    "    # Acta # *********************************\n",
    "    div = soup.find('div', class_='white-box')\n",
    "    h3 = div.find_all('h3')\n",
    "    h4 = div.find_all('h4')\n",
    "\n",
    "    titulo = h4[0].text.strip().lower()\n",
    "    presidente = h4[1].find('b').text\n",
    "    resolucion = h3[0].text\n",
    "\n",
    "    actas.append({\n",
    "        idActa:{\n",
    "            'periodo': periodo,\n",
    "            'reunion': reunion,\n",
    "            'acta': acta,\n",
    "            'titulo': titulo,\n",
    "            'presidente': presidente,\n",
    "            'resolucion': resolucion\n",
    "        }}\n",
    "    )\n",
    "\n",
    "    # Votacion # *********************************\n",
    "    tabla = soup.find('table', id='myTable')\n",
    "    rows = tabla.find_all('tr')\n",
    "    idVotacion = '{}-{}-{}'.format(periodo, reunion, acta)\n",
    "    cunt = 1\n",
    "    for r in rows:\n",
    "        cols = [x for x in r.find_all('td')]\n",
    "        if cols:\n",
    "            idDip = cols[0].find('div')['id']\n",
    "            voto = cols[4].text.strip().lower()\n",
    "            dichos = cols[5].text.strip().lower()\n",
    "\n",
    "        votaciones.append({\n",
    "            idVotacion: {\n",
    "                'idVoto': count,\n",
    "                'voto': voto,\n",
    "                'acta': idActa,\n",
    "                'dip': idDip,\n",
    "                'dichos': dichos\n",
    "            }\n",
    "        }\n",
    "        )\n",
    "    count += 1\n",
    "# **********************************************************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
